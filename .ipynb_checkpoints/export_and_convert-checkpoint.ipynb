{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9a74eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from googleapiclient.discovery import build\n",
    "from bs4 import BeautifulSoup\n",
    "import io\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# Path to your service account credentials JSON file\n",
    "credentials_path = r'C:\\Users\\eduar\\Downloads\\Export and Convert\\credentials.json'\n",
    "\n",
    "# Load the credentials from the JSON file\n",
    "credentials = service_account.Credentials.from_service_account_file(credentials_path, scopes=['https://www.googleapis.com/auth/drive'])\n",
    "\n",
    "service = build('drive', 'v3', credentials=credentials)\n",
    "\n",
    "def replace_drive_urls(html_content, download_directory):\n",
    "    pattern = r'https:\\/\\/drive\\.google\\.com\\/(?:file\\/d\\/|open\\?id=)([a-zA-Z0-9-_]+)'\n",
    "    urls = re.findall(pattern, html_content)\n",
    "\n",
    "    for url in urls:\n",
    "        file_id = url\n",
    "        response = service.files().get(fileId=file_id, fields='name').execute()\n",
    "        file_name = response['name']\n",
    "        local_path = os.path.join(download_directory, file_name)\n",
    "\n",
    "        # Download the file from Google Drive\n",
    "        request = service.files().get_media(fileId=file_id)\n",
    "        fh = io.FileIO(local_path, 'wb')\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "        done = False\n",
    "        while not done:\n",
    "            status, done = downloader.next_chunk()\n",
    "\n",
    "        html_content = html_content.replace(url, local_path)\n",
    "\n",
    "    return html_content\n",
    "\n",
    "\n",
    "def process_html_file(file_path, download_directory):\n",
    "    with open(file_path, 'r') as file:\n",
    "        html_content = file.read()\n",
    "\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    modified_html = replace_drive_urls(str(soup), download_directory)\n",
    "\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(modified_html)\n",
    "\n",
    "def process_html_files(directory, download_directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith('.html'):\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                process_html_file(file_path, download_directory)\n",
    "\n",
    "directory_path = r'Videos_1'\n",
    "download_directory_path = r'Videos_1'\n",
    "process_html_files(directory_path, download_directory_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
